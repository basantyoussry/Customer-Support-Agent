{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/basantyoussry/customer-support-agnet?scriptVersionId=224243421\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/basantyoussry/customer-support-agnet?scriptVersionId=223225101\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"# Customer-Support-Agent\nThis Customer Support Query Classification & Response Generation Model first classifies user queries into three categories: Order Issue, Payment Problem, and General Inquiry using a trained classifier. Based on the classification, it then generates a professional, natural-sounding response using LLaMA 2. The model ensures concise, helpful, and human-like replies while avoiding chatbot-like phrasing, making it ideal for automating customer support interactions.\n\nThis pipeline follows these steps:\n\n1️⃣ Query Classification:\n\nTrained a model on a small dataset consisting of two features: Query: The user's question or input. Category: The classification label with three possible classes: Order Issue Payment Problem General Inquiry Used Logistic Regression to classify the category of the query.\n\nUsed TF-IDF Vectorization to convert text queries into numerical format.\n\nEvaluated model performance using accuracy score and classification report.\n\n2️⃣ Response Generation:\n\nUsed LLaMA 2 to generate a response based on the classified category. Ensured responses are professional, natural, and helpful for customer support automation. This model efficiently automates customer service interactions by combining classification and text generation.","metadata":{}},{"cell_type":"markdown","source":"# Requirements\n\npandas\n\nscikit-learn\n\ntorch\n\ntransformers","metadata":{}},{"cell_type":"markdown","source":"# **Hugging Face Login & Model Access Instructions**\nIf you're running this on a different PC and need to access LLaMA 2, follow these steps:\n\n1️⃣ Visit the Model Page\n\nGo to LLaMA 2 on Hugging Face.\n2️⃣ Request Access\n\nClick \"Request Access\" and submit the form.\nApproval typically takes 5-10 minutes.\n3️⃣ Generate an Access Token\n\nOnce approved, go to Hugging Face Settings > Access Tokens.\nClick \"New Token\", give it a name, and set permissions to \"Write\".\n4️⃣ Grant Repository Permissions\n\nIn Repository Permissions, select LLaMA-2-7b-chat-hf to ensure access.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport time\nimport pymongo\nfrom huggingface_hub import login\nlogin()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:35:01.87927Z","iopub.execute_input":"2025-02-24T13:35:01.879628Z","iopub.status.idle":"2025-02-24T13:35:11.138236Z","shell.execute_reply.started":"2025-02-24T13:35:01.879598Z","shell.execute_reply":"2025-02-24T13:35:11.137317Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d55078cbe8de4ba1818e6590bf79336b"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"data = [\n    {\"query\": \"Where is my order?\", \"category\": \"Order Issue\"},\n    {\"query\": \"I want a refund.\", \"category\": \"Payment Problem\"},\n    {\"query\": \"How long does shipping take?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"Why was my card declined?\", \"category\": \"Payment Problem\"},\n    {\"query\": \"I received the wrong product.\", \"category\": \"Order Issue\"},\n    {\"query\": \"My order hasn't arrived yet.\", \"category\": \"Order Issue\"},\n    {\"query\": \"I was charged twice for my purchase.\", \"category\": \"Payment Problem\"},\n    {\"query\": \"Do you ship internationally?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"Can I change my shipping address?\", \"category\": \"Order Issue\"},\n    {\"query\": \"When will I receive my refund?\", \"category\": \"Payment Problem\"},\n    {\"query\": \"What payment methods do you accept?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"My package was damaged on arrival.\", \"category\": \"Order Issue\"},\n    {\"query\": \"I need to update my credit card details.\", \"category\": \"Payment Problem\"},\n    {\"query\": \"Do you offer discounts for bulk purchases?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"The tracking number is not working.\", \"category\": \"Order Issue\"},\n    {\"query\": \"How do I cancel my order?\", \"category\": \"Order Issue\"},\n    {\"query\": \"Why was my payment declined?\", \"category\": \"Payment Problem\"},\n    {\"query\": \"Do you provide customer support on weekends?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"Can I return an item I don’t like?\", \"category\": \"Order Issue\"},\n    {\"query\": \"How do I apply a discount code?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"I was charged the wrong amount.\", \"category\": \"Payment Problem\"},\n    {\"query\": \"My order status hasn’t been updated.\", \"category\": \"Order Issue\"},\n    {\"query\": \"Can I pay with cryptocurrency?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"Do you offer cash on delivery?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"I received an empty package.\", \"category\": \"Order Issue\"},\n    {\"query\": \"How do I reset my account password?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"I was charged after canceling my order.\", \"category\": \"Payment Problem\"},\n    {\"query\": \"How do I track my refund status?\", \"category\": \"Payment Problem\"},\n    {\"query\": \"I received a defective product.\", \"category\": \"Order Issue\"},\n    {\"query\": \"Is there a warranty on your products?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"Can I split my payment into installments?\", \"category\": \"Payment Problem\"},\n    {\"query\": \"The website crashed while I was paying.\", \"category\": \"Payment Problem\"},\n    {\"query\": \"My order was delivered to the wrong address.\", \"category\": \"Order Issue\"},\n    {\"query\": \"How do I change my billing information?\", \"category\": \"Payment Problem\"},\n    {\"query\": \"What happens if I'm not home when my order arrives?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"Do you offer gift wrapping?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"How do I report a fraudulent charge?\", \"category\": \"Payment Problem\"},\n    {\"query\": \"Can I pre-order an item?\", \"category\": \"General Inquiry\"},\n    {\"query\": \"My package is stuck in customs.\", \"category\": \"Order Issue\"}\n]\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\n\n# Display the DataFrame\n# df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:35:18.217302Z","iopub.execute_input":"2025-02-24T13:35:18.217719Z","iopub.status.idle":"2025-02-24T13:35:18.22742Z","shell.execute_reply.started":"2025-02-24T13:35:18.217686Z","shell.execute_reply":"2025-02-24T13:35:18.226658Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Checking Data Balance \ndf[\"category\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:35:21.53756Z","iopub.execute_input":"2025-02-24T13:35:21.537972Z","iopub.status.idle":"2025-02-24T13:35:21.55414Z","shell.execute_reply.started":"2025-02-24T13:35:21.537938Z","shell.execute_reply":"2025-02-24T13:35:21.552922Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"category\nOrder Issue        13\nPayment Problem    13\nGeneral Inquiry    13\nName: count, dtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Encode labels\nlabel_encoder = LabelEncoder()\ndf[\"category_encoded\"] = label_encoder.fit_transform(df[\"category\"])\nX=df[\"query\"]\ny=df[\"category_encoded\"]\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X,y ,test_size=0.2, random_state=42)\n\n# Convert text to TF-IDF vectors\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:35:23.916249Z","iopub.execute_input":"2025-02-24T13:35:23.916573Z","iopub.status.idle":"2025-02-24T13:35:23.942335Z","shell.execute_reply.started":"2025-02-24T13:35:23.916507Z","shell.execute_reply":"2025-02-24T13:35:23.941258Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# *Different Classifiaction Models*","metadata":{}},{"cell_type":"code","source":"# Training Logistic Regression Model\nmodel = LogisticRegression()\nmodel.fit(X_train_tfidf, y_train)\n\n# Predict on test set\ny_pred = model.predict(X_test_tfidf)\n\n# Evaluate performance\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:35:26.104945Z","iopub.execute_input":"2025-02-24T13:35:26.105235Z","iopub.status.idle":"2025-02-24T13:35:26.182955Z","shell.execute_reply.started":"2025-02-24T13:35:26.105213Z","shell.execute_reply":"2025-02-24T13:35:26.181591Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.375\nClassification Report:\n                  precision    recall  f1-score   support\n\nGeneral Inquiry       0.25      1.00      0.40         1\n    Order Issue       0.33      1.00      0.50         1\nPayment Problem       1.00      0.17      0.29         6\n\n       accuracy                           0.38         8\n      macro avg       0.53      0.72      0.40         8\n   weighted avg       0.82      0.38      0.33         8\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#Training Decision Tree Model\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train_tfidf, y_train)\n# Predict on test set\ny_pred_clf = clf.predict(X_test_tfidf)\n\n# Evaluate performance\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_clf))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_clf, target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:35:34.747958Z","iopub.execute_input":"2025-02-24T13:35:34.748238Z","iopub.status.idle":"2025-02-24T13:35:34.765846Z","shell.execute_reply.started":"2025-02-24T13:35:34.748216Z","shell.execute_reply":"2025-02-24T13:35:34.76484Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.5\nClassification Report:\n                  precision    recall  f1-score   support\n\nGeneral Inquiry       1.00      1.00      1.00         1\n    Order Issue       0.20      1.00      0.33         1\nPayment Problem       1.00      0.33      0.50         6\n\n       accuracy                           0.50         8\n      macro avg       0.73      0.78      0.61         8\n   weighted avg       0.90      0.50      0.54         8\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Training KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train_tfidf, y_train)\ny_pred_knn = knn.predict(X_test_tfidf)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:35:37.328091Z","iopub.execute_input":"2025-02-24T13:35:37.328499Z","iopub.status.idle":"2025-02-24T13:35:37.396042Z","shell.execute_reply.started":"2025-02-24T13:35:37.328462Z","shell.execute_reply":"2025-02-24T13:35:37.394477Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.375\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Testing the model with new data\ndef classify_query(query):\n    query_tfidf = vectorizer.transform([query])\n    category_index = clf.predict(query_tfidf)[0]\n    return label_encoder.inverse_transform([category_index])[0]\n\n# Test example\nprint(classify_query(\"My order is late\"))\nprint(classify_query(\"I have a problem\"))\nprint(classify_query(\"I was charged incorrectly\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:36:05.037081Z","iopub.execute_input":"2025-02-24T13:36:05.03743Z","iopub.status.idle":"2025-02-24T13:36:05.048555Z","shell.execute_reply.started":"2025-02-24T13:36:05.037402Z","shell.execute_reply":"2025-02-24T13:36:05.047707Z"}},"outputs":[{"name":"stdout","text":"Order Issue\nGeneral Inquiry\nPayment Problem\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"In the above example, although the model's accuracy is not high, it performs well on new data. However, due to the limited dataset size, which consists of only 40 samples, the evaluation may not be fully representative.","metadata":{}},{"cell_type":"code","source":"# while True:\n#     query=input(\"How may I help you?\")\n#     print(classify_query(query))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T14:35:55.159445Z","iopub.execute_input":"2025-02-18T14:35:55.159721Z","iopub.status.idle":"2025-02-18T14:35:55.162751Z","shell.execute_reply.started":"2025-02-18T14:35:55.159701Z","shell.execute_reply":"2025-02-18T14:35:55.162056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T14:35:59.139756Z","iopub.execute_input":"2025-02-18T14:35:59.140023Z","iopub.status.idle":"2025-02-18T14:35:59.162078Z","shell.execute_reply.started":"2025-02-18T14:35:59.140003Z","shell.execute_reply":"2025-02-18T14:35:59.161373Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# *Using Llama 2-7b for generating the response***","metadata":{}},{"cell_type":"code","source":"\n# token = \"\"  \n\nmodel_name = \"meta-llama/Llama-2-7b-chat-hf\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)  #, token=token\nllm = AutoModelForCausalLM.from_pretrained(\n    model_name, torch_dtype=torch.float16, device_map=\"auto\"\n) #, token=token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:36:44.703147Z","iopub.execute_input":"2025-02-24T13:36:44.703446Z","iopub.status.idle":"2025-02-24T13:38:16.757815Z","shell.execute_reply.started":"2025-02-24T13:36:44.703424Z","shell.execute_reply":"2025-02-24T13:38:16.757049Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d7378b005cf42fab2efa39bb21aa35d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1bdfd28794748ee96ba3ace92d63fd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0eecd852fbb4be4ac3c72ddba8bd272"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a516a4e44a4a828c137b2d809a1871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"668e5332f98f42faacda44f3c84729ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7f3d639d744474bbb6b1b53ee34f140"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3537020c657425caaa7888fb5e24b49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb794f5824b34ba8a84212953819f01f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1b616cd585445b8202615182fc3605"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51da48c95694428086aa4c2dda380318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1332c8ea19a4655bcdc24df4eae7b44"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# *Testing the model***","metadata":{}},{"cell_type":"code","source":"def generate_response(query):\n    category = classify_query(query)\n    print(category)\n    # Define category-based prompts\n    prompts = {\n        \"You are professional Customer Support Agent. elping Customer with their queries do not give additional information than the question asked. if the enquery about order issue ask them about order number\"\n        \"Order Issue\": \"You are a professional Customer Support Agent. Use natural language and avoid chatbot-like responses. \"\n                       \"The user is experiencing an issue with their order. Respond professionally and helpfully.\",\n        \"Payment Problem\": \"You are a professional Customer Support Agent. Use natural language and avoid chatbot-like responses. \"\n                           \"The user has a payment-related issue. Guide them with possible solutions.\",\n        \"General Inquiry\": \"You are a professional Customer Support Agent. Use natural language and avoid chatbot-like responses. \"\n                           \"The user has a general question. Provide useful and concise information.\"\n    }\n    \n    # Format the prompt for LLaMA 2\n    full_prompt = f\"{prompts[category]}\\n\\nUser: {query}\\nSupport Agent:\"\n\n    # Tokenize and generate response\n    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n    output = llm.generate(**inputs, max_length=100, temperature=0.7, top_p=0.9)\n\n    # Decode and return the response\n    response = tokenizer.decode(output[0], skip_special_tokens=True)\n    return response\n\n# Example Usage\n# print(generate_response(\"I want to track my order.\"))\n# print(generate_response(\"Why was my payment declined?\"))\n# print(generate_response(\"Do you offer international shipping?\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:19:31.7599Z","iopub.execute_input":"2025-02-24T14:19:31.760216Z","iopub.status.idle":"2025-02-24T14:19:31.765116Z","shell.execute_reply.started":"2025-02-24T14:19:31.760189Z","shell.execute_reply":"2025-02-24T14:19:31.764174Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"while True:\n    query= input(\"How may I help you?\")\n    response= classify_query(query)\n    print(\"Human Question: \",response)\n    ai_response =generate_response(query)\n    print(\"AI Response:\", ai_response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:19:36.130113Z","iopub.execute_input":"2025-02-24T14:19:36.130388Z","execution_failed":"2025-02-24T17:03:12.092Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"How may I help you? hello\n"},{"name":"stdout","text":"Human Question:  General Inquiry\nGeneral Inquiry\nAI Response: You are a professional Customer Support Agent. Use natural language and avoid chatbot-like responses. The user has a general question. Provide useful and concise information.\n\nUser: hello\nSupport Agent: Hello! How can I help you today? \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"How may I help you? I have made an order yesterday\n"},{"name":"stdout","text":"Human Question:  General Inquiry\nGeneral Inquiry\nAI Response: You are a professional Customer Support Agent. Use natural language and avoid chatbot-like responses. The user has a general question. Provide useful and concise information.\n\nUser: I have made an order yesterday\nSupport Agent: Hi there! I'm so sorry to hear that you're having trouble with your order. Can you please provide me with more details about the issue you're experiencing? For example, did you receive an order confirmation email, and do\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"After refining the prompt, I achieved a smooth and professional response that effectively assists the user.","metadata":{}}]}